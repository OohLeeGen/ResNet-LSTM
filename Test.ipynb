{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c9a16b8-80b7-4f1d-888b-f077be437508",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-05-28T16:20:11.374212Z",
     "end_time": "2024-05-28T16:20:13.281309Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "from PIL import Image\n",
    "import torch\n",
    "import os\n",
    "import torchvision.models as models\n",
    "from torchvision.transforms import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((400, 400)),  # 将图像大小统一调整到400x400\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "class ImgSeq(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.data = []  # 用于存储完整图像路径\n",
    "        self.labels = []  # 用于存储图像对应的标签\n",
    "        self.folder_path=[]\n",
    "        # 路径操作 遍历图片序列文件夹，收集数据和标签\n",
    "        for index, sub_path_name in enumerate(['injFail', 'injSuccess']):\n",
    "            dir_path = os.path.join(root_dir, sub_path_name)  # 构造文件夹路径\n",
    "            for folder_name in os.listdir(dir_path):  # 遍历文件夹中的所有文件\n",
    "                path = os.path.join(dir_path, folder_name)  # 构造序列文件夹的完整路径\n",
    "                if os.path.isdir(path):  # 检查是否为目录\n",
    "                    self.folder_path.append(path)\n",
    "                    self.data.append([os.path.join(path, img) for img in sorted(os.listdir(path))])\n",
    "                    # sorted保证序列的顺序性，防止序列图片被打乱\n",
    "                    self.labels.append(index)  # 保存对应的标签（0为失败，1为成功）\n",
    "    def __len__(self):# 定义类的长度返回方法\n",
    "        return len(self.data)\n",
    "    def __getitem__(self, idx): # 定义getitem方法 允许类使用索引操作\n",
    "        img_seq = self.data[idx] # 取对应索引的图片序列\n",
    "        images = [Image.open(img).convert('L') for img in img_seq]  # PIL库的图片操作 转化为灰度图\n",
    "        images = [self.transform(img) for img in images]  # 对每个图像应用预处理变换\n",
    "        images = torch.stack(images)  # 图像堆叠成新张量\n",
    "        label = self.labels[idx]\n",
    "        return images, label  # 返回处理后的图像堆叠和标签\n",
    "    pass\n",
    "### 所有网络模块的定义\n",
    "# 定义CNN模块，用于特征提取\n",
    "class SqCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SqCNN, self).__init__()\n",
    "        # 加载预训练的模型单通道输入ResNet-50预训练模型\n",
    "        resnet = models.resnet18(pretrained=True)\n",
    "        resnet.conv1 = nn.Conv2d(1, 64, kernel_size=(3, 3), stride=(2, 2), padding=(2, 2), bias=False)\n",
    "        # 迁移学习，我们需要去除最后一个全连接层\n",
    "        # 重用ResNet的特征提取能力，而用自己的分类层替换掉原有的分类层，以便适应新的任务或类别数。\n",
    "        self.features = nn.Sequential(*list(resnet.children())[:-1])\n",
    "        # 添加Dropout层，用于减少过拟合\n",
    "        self.dropout = nn.Dropout(p=0.3)\n",
    "    def forward(self, x):\n",
    "        # x的维度是[batch_size, seq_len, channels, height, width]\n",
    "        # 正确的维度应该是：4 8 1 400 400\n",
    "        batch_size, seq_len, c, h, w = x.size()\n",
    "        # 合并批次和序列长度，使其适合CNN输入\n",
    "        x = x.view(batch_size * seq_len, c, h, w)\n",
    "        x = self.features(x)\n",
    "        # 重新解放维度，还原批次和序列长度\n",
    "        x = x.view(batch_size, seq_len, -1)\n",
    "        x = self.dropout(x)\n",
    "        return x\n",
    "# 定义LSTM与注意力机制模块\n",
    "class LSTMWithAttention(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers, num_classes):\n",
    "        super(LSTMWithAttention, self).__init__()\n",
    "        # 定义LSTM层\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True)\n",
    "        # 添加Dropout层\n",
    "        self.dropout = nn.Dropout(p=0.3)\n",
    "        # 定义注意力层，用于为每个时间步的隐藏状态分配权重\n",
    "        self.attention_layer = nn.Linear(hidden_dim, 1)\n",
    "        # 定义全连接层，用于分类\n",
    "        self.fc = nn.Linear(hidden_dim, num_classes)\n",
    "    def forward(self, x):\n",
    "        # 通过LSTM处理输入\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        # 应用Dropout\n",
    "        lstm_out = self.dropout(lstm_out)\n",
    "        # 生成注意力权重\n",
    "        attention_weights = torch.softmax(self.attention_layer(lstm_out), dim=1)\n",
    "        # 计算加权的上下文向量\n",
    "        context_vector = torch.sum(lstm_out * attention_weights, dim=1)\n",
    "        # 通过全连接层得到最终输出\n",
    "        out = self.fc(context_vector)\n",
    "        return out\n",
    "# 整体模型结构 串联CNN和LSTM两个模型\n",
    "class CNNLSTM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNLSTM, self).__init__()\n",
    "        # 初始化CNN特征提取器\n",
    "        self.cnn = SqCNN()\n",
    "        # 初始化LSTM与注意力机制模块\n",
    "        self.lstm_attention = LSTMWithAttention(input_dim=512, hidden_dim=128, num_layers=1, num_classes=2)\n",
    "    def forward(self, x):\n",
    "        # 从CNN获取特征\n",
    "        cnn_features = self.cnn(x)\n",
    "        # 使用特征通过LSTM和注意力机制模块得到输出\n",
    "        output = self.lstm_attention(cnn_features)\n",
    "        return output\n",
    "# 加载模型函数\n",
    "def load_model(model_path):\n",
    "    model = CNNLSTM()\n",
    "    model.load_state_dict(torch.load(model_path))  # 加载模型参数\n",
    "    model.eval()  # 模型设为评估模式\n",
    "    return model\n",
    "# 预测函数，并计算准确率\n",
    "def predict(model, data_loader):\n",
    "    model.eval()  # 模型设为评估模式\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    results = []\n",
    "    model = model.to(device)\n",
    "    with torch.no_grad():  # 禁用梯度计算\n",
    "        for images, labels in data_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)  # 前向传播\n",
    "            _, predicted = outputs.max(1)  # 获取预测结果\n",
    "            results.extend(predicted.cpu().numpy())  # 将结果存入列表\n",
    "            # 累计正确的预测数量\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()  # 累加正确预测数\n",
    "            pass\n",
    "        pass\n",
    "    accuracy = correct / total\n",
    "    return results, accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\29797\\.conda\\envs\\pytorch_use\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\29797\\.conda\\envs\\pytorch_use\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# 这是对外接口，改变参数就可以测试了\n",
    "model = load_model(\"model.pth\") # 模型加载接口\n",
    "folder_name='injection-dataset_test' # 测试用例父路径接口"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-28T16:20:13.284839Z",
     "end_time": "2024-05-28T16:20:13.826785Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae951234-80c4-441a-845b-90365e42f3c4",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-05-28T16:20:13.819267Z",
     "end_time": "2024-05-28T16:20:41.550520Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "以下是预测结果\n",
      "injection-dataset_test\\injFail\\MyVideo_33 : Fail\n",
      "injection-dataset_test\\injFail\\MyVideo_34 : Fail\n",
      "injection-dataset_test\\injFail\\MyVideo_35 : Fail\n",
      "injection-dataset_test\\injFail\\MyVideo_36 : Fail\n",
      "injection-dataset_test\\injFail\\MyVideo_37 : Fail\n",
      "injection-dataset_test\\injFail\\MyVideo_38 : Fail\n",
      "injection-dataset_test\\injFail\\MyVideo_39 : Fail\n",
      "injection-dataset_test\\injFail\\MyVideo_40 : Fail\n",
      "injection-dataset_test\\injSuccess\\MyVideo_33 : Success\n",
      "injection-dataset_test\\injSuccess\\MyVideo_34 : Success\n",
      "injection-dataset_test\\injSuccess\\MyVideo_35 : Success\n",
      "injection-dataset_test\\injSuccess\\MyVideo_36 : Success\n",
      "injection-dataset_test\\injSuccess\\MyVideo_37 : Success\n",
      "injection-dataset_test\\injSuccess\\MyVideo_38 : Success\n",
      "injection-dataset_test\\injSuccess\\MyVideo_39 : Success\n",
      "injection-dataset_test\\injSuccess\\MyVideo_40 : Success\n",
      "Accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "# 加载测试数据集\n",
    "test_dataset = ImgSeq(root_dir=folder_name, transform=transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=4, shuffle=False, num_workers=0)\n",
    "# 进行预测并计算准确率\n",
    "predictions, accuracy = predict(model, test_loader)\n",
    "# 输出预测结果\n",
    "print(f'以下是预测结果')\n",
    "for i, prediction in enumerate(predictions):\n",
    "    print(f'{test_dataset.folder_path[i]} : {\"Success\" if prediction == 1 else \"Fail\"}')\n",
    "print(f'Accuracy: {accuracy * 100:.2f}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
